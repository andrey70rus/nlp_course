{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "11.8333px",
        "width": "160px"
      },
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "339.717px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PcL7r1hqySq"
      },
      "source": [
        "# Предобработка текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sGLT0vp4jt"
      },
      "source": [
        "## Часть 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn8EWAjnr18g"
      },
      "source": [
        "### Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btBdBLxbgrNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6743892b-59b5-4c27-dfe7-f2450cda73cd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq-QOD9NlO_Q"
      },
      "source": [
        "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
        "tokens = word_tokenize(data.lower())\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFDKUzkS6Mci"
      },
      "source": [
        "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQoG7qznyuf5"
      },
      "source": [
        "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPeApu2mwYxY"
      },
      "source": [
        "[Razdel](https://natasha.github.io/razdel/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwJj5Z2fvbeN"
      },
      "source": [
        "!pip install -q razdel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy58Xd_vve-z"
      },
      "source": [
        "from razdel import tokenize, sentenize\n",
        "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
        "list(tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrmhCpNdQo6r"
      },
      "source": [
        "#### Регулярные выражения\n",
        "\n",
        "Исчерпывающий пост https://habr.com/ru/post/349860/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IccRpcG06Mfd"
      },
      "source": [
        "import re\n",
        "word = 'supercalifragilisticexpialidocious'\n",
        "re.findall('[abc]|up|super', word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je8YPHLZPJW7"
      },
      "source": [
        "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzde8MX1PJXA"
      },
      "source": [
        "re.sub('[,\\.?!]','','How, to? split. text!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyswV9nuPJXF"
      },
      "source": [
        "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0wIRkRswOQ"
      },
      "source": [
        "### Удаление неинформативных слов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trdPOBM2jEMf"
      },
      "source": [
        "#### N-граммы\n",
        "\n",
        "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYEBfCxLic3R"
      },
      "source": [
        "unigram = list(nltk.ngrams(tokens, 1))\n",
        "bigram = list(nltk.ngrams(tokens, 2))\n",
        "print(unigram[:5])\n",
        "print(bigram[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AFeZqejmWwN"
      },
      "source": [
        "from nltk import FreqDist\n",
        "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
        "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W3jJ56hnBFu"
      },
      "source": [
        "#### Стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIBwQ3nBnEfV"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1nk-TqEslRl"
      },
      "source": [
        "stopWords = set(stopwords.words('russian'))\n",
        "print(stopWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFkfJm9ktAVa"
      },
      "source": [
        "print([word for word in tokens if word not in stopWords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5QoqlHiS83f"
      },
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh-MYv6e-skM"
      },
      "source": [
        "#### Стемминг vs Лемматизация\n",
        "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
        "* ‘Caring’ -> Стемминг -> ‘Car’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAUKc1oTiQjf"
      },
      "source": [
        "### Стемминг\n",
        "* процесс нахождения основы слова для заданного исходного слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRVu-TrON4sq"
      },
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
        "words_ru = ['корова', 'мальчики', 'мужчи', 'столом', 'убежала']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9HTGfsBN9eX"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "list(map(ps.stem, words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qZkB-oODkW"
      },
      "source": [
        "ss = SnowballStemmer(language='russian')\n",
        "list(map(ss.stem, words_ru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbTXbi9FJXr1"
      },
      "source": [
        "### Лематизация\n",
        "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4nnEz00thb"
      },
      "source": [
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно \n",
        "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на \n",
        "устаревших представлениях об устройстве мозга, несовместимо с современной \n",
        "неврологией и содержит ряд фактических ошибок.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mljfOAC4n21I",
        "outputId": "cf189118-1044-4f31-9aae-bb34d6effdcd"
      },
      "source": [
        "!pip install -q pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zez7jnXl5uJ",
        "outputId": "0f10b8f7-cf5d-469d-fbff-c3b1a31d5353"
      },
      "source": [
        "# 1\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
        "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "не существовать научный доказательство в польза эффективность нлп, оно \n",
            "признать псевдонаукой. систематический обзор указывают, что нлп основать на \n",
            "устаревший представление о устройство мозга, несовместимый с современный \n",
            "неврология и содержать ряд фактический ошибок.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7MDqIvWib4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "cef8da16-8cf2-4909-a546-620a944d0d7e"
      },
      "source": [
        "# 2\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "spacy_results = nlp(raw)\n",
        "print(' '.join([token.lemma_ for token in spacy_results]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-44aba60b3fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mspacy_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspacy_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVC5gjCRk5bD"
      },
      "source": [
        "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yim_NVYA6MeS"
      },
      "source": [
        "### Part-of-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t_MamYKqbSk",
        "outputId": "17c3a9fc-4fc2-4d0f-9353-a76e653cf6f0"
      },
      "source": [
        "# 1\n",
        "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', OpencorporaTag('PRCL')),\n",
              " ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n",
              " ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n",
              " ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n",
              " ('в', OpencorporaTag('PREP')),\n",
              " ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n",
              " ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n",
              " ('нлп,', OpencorporaTag('UNKN')),\n",
              " ('оно', OpencorporaTag('NPRO,neut,3per,Anph sing,nomn'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doa85yw6JWea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794ec981-0378-4020-e316-f1e2045d8949"
      },
      "source": [
        "# 2\n",
        "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('denni', 'NOUN'),\n",
              " (':', 'PUNCT'),\n",
              " ('listen', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('strange', 'ADJ'),\n",
              " ('woman', 'NOUN'),\n",
              " ('lie', 'VERB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVGJLVjLtFDp",
        "outputId": "c01be447-80df-4477-c875-28889e7b7e36"
      },
      "source": [
        "!pip install -q rnnmorph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 10.5MB 6.2MB/s \n",
            "\u001b[?25h  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ms2yeEFqrtZ",
        "outputId": "dd9131e0-82bd-46a7-e54e-1bed989ff9fb"
      },
      "source": [
        "# 3\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
        "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 'PART', '_'),\n",
              " ('существовать',\n",
              "  'VERB',\n",
              "  'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'),\n",
              " ('научный', 'ADJ', 'Case=Gen|Degree=Pos|Number=Plur'),\n",
              " ('доказательство', 'NOUN', 'Case=Gen|Gender=Neut|Number=Plur'),\n",
              " ('в', 'ADP', '_'),\n",
              " ('польза', 'NOUN', 'Case=Acc|Gender=Fem|Number=Sing'),\n",
              " ('эффективность', 'NOUN', 'Case=Gen|Gender=Fem|Number=Sing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Slt2R76Mgk"
      },
      "source": [
        "### Named entities recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvB43ZHT6MhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d490cfc-0b7f-4cb1-f655-7e9ca16f6a2d"
      },
      "source": [
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0-_oFwwqAwN"
      },
      "source": [
        "## Часть 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIwDfmrYOMfi"
      },
      "source": [
        "### Задача классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6DaLniC6MhY"
      },
      "source": [
        "#### 20 newsgroups\n",
        "Датасет с 18000 новостей, сгруппированных по 20 темам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uS7IJNW6Mhb"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMbagpJE6Mhh",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7a53a2-3a2b-4b3d-bd42-7252390aa2ba"
      },
      "source": [
        "newsgroups_train.target_names"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(newsgroups_train.data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSw5_c4R0Ph",
        "outputId": "98b73774-6cec-4add-fd39-febe3dd8cf4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
            "Subject: SI Clock Poll - Final Call\n",
            "Summary: Final call for SI clock reports\n",
            "Keywords: SI,acceleration,clock,upgrade\n",
            "Article-I.D.: shelley.1qvfo9INNc3s\n",
            "Organization: University of Washington\n",
            "Lines: 11\n",
            "NNTP-Posting-Host: carson.u.washington.edu\n",
            "\n",
            "A fair number of brave souls who upgraded their SI clock oscillator have\n",
            "shared their experiences for this poll. Please send a brief message detailing\n",
            "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
            "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
            "functionality with 800 and 1.4 m floppies are especially requested.\n",
            "\n",
            "I will be summarizing in the next two days, so please add to the network\n",
            "knowledge base if you have done the clock upgrade and haven't answered this\n",
            "poll. Thanks.\n",
            "\n",
            "Guy Kuo <guykuo@u.washington.edu>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QReW1K46Mhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d243da37-1e2a-4a19-e22b-960f369915c7"
      },
      "source": [
        "newsgroups_train.filenames.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZtRIQmNQ4H0"
      },
      "source": [
        "#### Рассмотрим подвыборку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhwuCp5B6Mhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aba43ff-b96f-4677-95d1-a9b6431515f3"
      },
      "source": [
        "categories = ['alt.atheism', 'talk.religion.misc',\n",
        "              'comp.graphics', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      categories=categories)\n",
        "newsgroups_train.filenames.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOREsv336MiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91d5c50-4e47-4ba9-cbbe-37acf3df847a"
      },
      "source": [
        "print(newsgroups_train.data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: rych@festival.ed.ac.uk (R Hawkes)\n",
            "Subject: 3DS: Where did all the texture rules go?\n",
            "Lines: 21\n",
            "\n",
            "Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "\n",
            "======================================================================\n",
            "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
            "Virtual Environment Laboratory\n",
            "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
            "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
            "======================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBnDG-TN6MiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbbadf6-b194-4fb8-b945-e8f2e67d7250"
      },
      "source": [
        "newsgroups_train.target[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XlZYpodRYDI"
      },
      "source": [
        "#### TF-IDF(напоминание)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUk2n3jRbNp"
      },
      "source": [
        "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
        "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
        "$N$ - число документов; <br><br>\n",
        "\n",
        "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
        "<br>\n",
        "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
        "\n",
        "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
        "\n",
        "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
        "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQvcMiFH6MiM"
      },
      "source": [
        "#### Давайте векторизуем эти тексты с помощью TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98LLAoZO6MiU"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baXLU0lj6MiY"
      },
      "source": [
        "#### Некоторые параметры: \n",
        "* input : string {‘filename’, ‘file’, ‘content’}\n",
        "*  lowercase : boolean, default True\n",
        "*  preprocessor : callable or None (default)\n",
        "*  tokenizer : callable or None (default)\n",
        "*  stop_words : string {‘english’}, list, or None (default)\n",
        "*  ngram_range : tuple (min_n, max_n)\n",
        "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
        "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
        "*  max_features : int or None, default=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-m81BJxZFwJ"
      },
      "source": [
        "#### Перебор параметров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f7padHL6MiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8a47e3-19f4-48a7-a99c-d61198775fa3"
      },
      "source": [
        "# lowercase\n",
        "vectorizer = TfidfVectorizer(lowercase=True)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 34118)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectors[0,:])"
      ],
      "metadata": {
        "id": "fbcJm_BfWSak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names()[-10:]"
      ],
      "metadata": {
        "id": "p0hOgH5rTiiO",
        "outputId": "119cefd9-3df9-41b8-8b44-bb9f6ac56b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zwak',\n",
              " 'zwakke',\n",
              " 'zware',\n",
              " 'zwarte',\n",
              " 'zxmkr08',\n",
              " 'zyeh',\n",
              " 'zyxel',\n",
              " 'ªL',\n",
              " 'º_________________________________________________º_____________________º',\n",
              " 'ºnd']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf2s4HCY6Mie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b818b205-027c-4f72-8b6f-e4d5c361879d"
      },
      "source": [
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 42307)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hwlTWapZR8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fa5176-cd69-4dd2-8dc4-2fbbe19678ed"
      },
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '00000',\n",
              " '000000',\n",
              " '000005102000',\n",
              " '000021',\n",
              " '000062David42',\n",
              " '0000VEC',\n",
              " '0001']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYfpk0ds6Mij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd75f09-a99b-4ed1-bba4-2928e4d752b0"
      },
      "source": [
        "# min_df, max_df\n",
        "vectorizer = TfidfVectorizer(min_df=0.8)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ookt99atZ8sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ada971a-037a-4dff-fe05-191121d5dfde"
      },
      "source": [
        "vectorizer.get_feature_names()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'from', 'in', 'lines', 'of', 'organization', 'subject', 'the', 'to']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e_h6c0X6Mim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db3bb38-2c0b-460f-f75d-ea68a6fa578a"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 2391)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "metadata": {
        "id": "r832HK2GW32a",
        "outputId": "6ad890e6-ed2f-41c2-ca72-e1a9312fd7f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00', '000', '01', '02', '04', '06', '10', '100', '1000', '11']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUhOyx4NihL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80029202-1799-4bff-8f4c-8e052887200a"
      },
      "source": [
        "# ngram_range\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 1236)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names()[:10]"
      ],
      "metadata": {
        "id": "cCLjAjr3XVVx",
        "outputId": "2fb6c09a-d117-40a3-a71a-db769d5bb2f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000', '10', '100', '11', '12', '13', '14', '15', '16', '17']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7074cdSF6MjC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1ca5c231-eb71-42eb-d4a3-f9bc1f1780c3"
      },
      "source": [
        "# стоп-слова, preproc\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stopWords = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "def preproc_nltk(text):\n",
        "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
        "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
        "\n",
        "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
        "preproc_nltk(st)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'oh , think landed miracle work , thirst hunger come conference bird'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIW3hCSy6MjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc11d79-ae17-4bf1-bd6f-b3e093b76064"
      },
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.4 s, sys: 25.9 ms, total: 10.4 s\n",
            "Wall time: 12.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lUmyAzJEB1SU",
        "outputId": "c7779f39-a02a-4185-ea8b-4691a144631b"
      },
      "source": [
        "# preproc_spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "texts = newsgroups_train.data.copy()\n",
        "\n",
        "def preproc_spacy(text):\n",
        "    spacy_results = nlp(text)\n",
        "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
        "preproc_spacy(st)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'oh , I think I land miracle work ,   thirst hunger come conference bird'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C5Ent0nG5zj",
        "outputId": "f0bb5f9b-891c-4f96-f152-e0e9a0f2231d"
      },
      "source": [
        "%%time\n",
        "new_texts = []\n",
        "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
        "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(new_texts)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 14.2 s, sys: 421 ms, total: 14.6 s\n",
            "Wall time: 1min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lXAPHZA6Mj0"
      },
      "source": [
        "#### Итоговая модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZYcRkQ86Mj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec0c987-a022-450e-bd8b-935ce8a6318b"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
        "vectors = vectorizer.fit_transform(new_texts)\n",
        "vectorizer.get_feature_names()[::100]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000',\n",
              " 'attempt',\n",
              " 'christ',\n",
              " 'end',\n",
              " 'however',\n",
              " 'look',\n",
              " 'of this',\n",
              " 'report',\n",
              " 'technology',\n",
              " 'understand']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQHTlj3q6Mj6"
      },
      "source": [
        "#### Можем посмотреть на косинусную меру между векторами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4fKtAXqCl-",
        "outputId": "fb44e2e9-3263-4fbe-ee9b-3c71b154ed78"
      },
      "source": [
        "vectors.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA8Fn5I46Mi0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1997d43-a964-455b-de5e-0cb1cd08c7d9"
      },
      "source": [
        "vector = vectors.todense()[0]\n",
        "(vector != 0).sum()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "iulBvQvEaP6K"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kweWqI8ztDwC",
        "outputId": "9be2ee1f-0496-45d5-a9c5-54c52fdcd013"
      },
      "source": [
        "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.93952802359883"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsVQhR9y6Mj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b5daef-5f25-4986-efe2-a2b57ededf56"
      },
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "type(vectors)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS2G0ZZC6MkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6041b546-b527-45b1-fe8c-3459f0f5c3f8"
      },
      "source": [
        "dense_vectors = vectors.todense()\n",
        "dense_vectors.shape"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2034, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGgb5aP76MkU"
      },
      "source": [
        "def cosine_sim(v1, v2):\n",
        "    # v1, v2 (1 x dim) \n",
        "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_FrKM6k6MkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150"
      },
      "source": [
        "cosine_sim(dense_vectors[0], dense_vectors[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000000000000002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1XF-isH6Mkh"
      },
      "source": [
        "cosines = []\n",
        "for i in range(10):\n",
        "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODwgYEbe6Mkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6959653-9dea-438a-9590-9c2afedceab4"
      },
      "source": [
        "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
        "cosines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0000000000000002,\n",
              " 0.043294587352860875,\n",
              " 0.005869835524491915,\n",
              " 0.0935800085948649,\n",
              " 0.042441093346628496,\n",
              " 0.04763556598669193,\n",
              " 0.038723466540658134,\n",
              " 0.22771527506874503,\n",
              " 0.03289646848736767,\n",
              " 0.06184884190504455]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRZyJP3c6Mkq"
      },
      "source": [
        "#### Обучим любую известную модель на полученных признаках"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RDfl72A6Mks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b1cd39-423d-4e7a-924a-58adf16d7cd4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627,), (407,))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjfwduNp6Mlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c824e60-b145-4e9b-fdaa-6a12ecd681fd"
      },
      "source": [
        "%%time\n",
        "svc = svm.SVC()\n",
        "svc.fit(X_train, y_train)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.68 s, sys: 2.07 ms, total: 1.68 s\n",
            "Wall time: 1.75 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Evwipx6Mlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eff8243-ddfe-4d15-d948-b7e833b085da"
      },
      "source": [
        "accuracy_score(y_test, svc.predict(X_test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.918918918918919"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EBZRbXT6Mly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4"
      },
      "source": [
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "accuracy_score(y_test, sgd.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8968058968058968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5OAwBJ0LuPb"
      },
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLGAYPvPJcJ"
      },
      "source": [
        "import gensim.downloader as api\n",
        "embeddings_pretrained = api.load('glove-twitter-25')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmH3vc7FSCuP"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
        "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
        "                 size=100,                 # embedding vector size\n",
        "                 min_count=3,             # consider words that occured at least 5 times\n",
        "                 window=3).wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lq20widPJcO"
      },
      "source": [
        "def vectorize_sum(comment, embeddings):\n",
        "    \"\"\"\n",
        "    implement a function that converts preprocessed comment to a sum of token vectors\n",
        "    \"\"\"\n",
        "    embedding_dim = embeddings.vectors.shape[1]\n",
        "    features = np.zeros([embedding_dim], dtype='float32')\n",
        "\n",
        "    for word in preproc_nltk(comment).split():\n",
        "        if word in embeddings:\n",
        "            features += embeddings[f'{word}']\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1KaMKBHsSHd",
        "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
      },
      "source": [
        "len(embeddings_trained.index2word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krjpVRsLPJcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
      },
      "source": [
        "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
        "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "X_train_wv.shape, X_test_wv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627, 25), (407, 25))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWhQ007PPJcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(max_iter=5000)\n",
        "wv_model = clf.fit(X_train_wv, y_train)\n",
        "accuracy_score(y_test, wv_model.predict(X_test_wv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7100737100737101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT_Rr4nOUUu8",
        "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
      },
      "source": [
        "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
        "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
        "X_train_wv.shape, X_test_wv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1627, 100), (407, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVMeZBLbVMjO",
        "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(max_iter=10000)\n",
        "wv_model = clf.fit(X_train_wv, y_train)\n",
        "accuracy_score(y_test, wv_model.predict(X_test_wv))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8402948402948403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_K8NLmDVds1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}